{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, error_function='gini'):\n",
        "        self.error_function = error_function\n",
        "        self.model = {}\n",
        "\n",
        "        #Calculate the Gini impurity\n",
        "    def gini(self, y):\n",
        "        classes, counts = np.unique(y, return_counts=True)\n",
        "        probabilities = counts / len(y)\n",
        "        return 1 - np.sum(probabilities**2)\n",
        "\n",
        "        #Calculate the entropy\n",
        "    def entropy(self, y):\n",
        "        from scipy.stats import entropy\n",
        "        classes, counts = np.unique(y, return_counts=True)\n",
        "        probabilities = counts / len(y)\n",
        "        return entropy(probabilities, base=2)\n",
        "\n",
        "        #Train the decision tree\n",
        "    def train(self, X, y, hyperparameters):\n",
        "        unique_classes = np.unique(y)\n",
        "        if len(unique_classes) == 1:\n",
        "            self.model = {'label': unique_classes[0]}\n",
        "        else:\n",
        "            best_gini = float('inf')\n",
        "            best_split = None\n",
        "            best_left_labels = None\n",
        "            best_right_labels = None\n",
        "\n",
        "            # Search for the best split\n",
        "            for feature in range(X.shape[1]):\n",
        "                thresholds = np.unique(X[:, feature])\n",
        "                for threshold in thresholds:\n",
        "                    left_indices = X[:, feature] <= threshold\n",
        "                    right_indices = X[:, feature] > threshold\n",
        "                    left_labels = y[left_indices]\n",
        "                    right_labels = y[right_indices]\n",
        "\n",
        "                    gini_left = self.gini(left_labels)\n",
        "                    gini_right = self.gini(right_labels)\n",
        "                    weighted_gini = (len(left_labels) / len(y)) * gini_left + (len(right_labels) / len(y)) * gini_right\n",
        "\n",
        "                    if weighted_gini < best_gini:\n",
        "                        best_gini = weighted_gini\n",
        "                        best_split = threshold\n",
        "                        best_left_labels = left_labels\n",
        "                        best_right_labels = right_labels\n",
        "\n",
        "            self.model = {\n",
        "                'feature': 0,\n",
        "                'threshold': best_split,\n",
        "                'children': {\n",
        "                    'left': {'label': np.argmax(np.bincount(best_left_labels))},\n",
        "                    'right': {'label': np.argmax(np.bincount(best_right_labels))}\n",
        "                }\n",
        "            }\n",
        "\n",
        "        #Predict the labels for the data\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for row in X:\n",
        "            node = self.model\n",
        "            while 'children' in node:\n",
        "                if row[node['feature']] <= node['threshold']:\n",
        "                    node = node['children']['left']\n",
        "                else:\n",
        "                    node = node['children']['right']\n",
        "            predictions.append(node['label'])\n",
        "        return predictions\n",
        "\n",
        "class RandomForest:\n",
        "    def __init__(self):\n",
        "        self.trees = []\n",
        "        self.num_trees = 0\n",
        "\n",
        "        #Train the random forest using bagging.\n",
        "    def train(self, X, y, hyperparameters):\n",
        "        self.num_trees = hyperparameters.get('num_trees', 10)\n",
        "        error_function = hyperparameters.get('error_function', 'gini')\n",
        "        self.trees = []\n",
        "        for _ in range(self.num_trees):\n",
        "            # Shuffle the dataset\n",
        "            indices = np.arange(len(X))\n",
        "            np.random.shuffle(indices)\n",
        "            subset_size = int(0.8 * len(X))\n",
        "            subset_indices = indices[:subset_size]\n",
        "            # Subset the data\n",
        "            X_subset = X[subset_indices]\n",
        "            y_subset = y[subset_indices]\n",
        "            # Train a decision tree\n",
        "            tree = DecisionTree(error_function=error_function)\n",
        "            tree.train(X_subset, y_subset, {'error_function': error_function})\n",
        "            self.trees.append(tree)\n",
        "\n",
        "        #Predict the labels using the random forest (majority vote).\"\"\"\n",
        "    def predict(self, X):\n",
        "        if not self.trees:\n",
        "            raise ValueError(\"The forest has not been trained yet.\")\n",
        "        # Collect predictions from each tree\n",
        "        tree_predictions = []\n",
        "        for tree in self.trees:\n",
        "            # Predict with the tree and ensure the result is numeric\n",
        "            tree_preds = np.array(tree.predict(X))\n",
        "            tree_predictions.append(tree_preds.astype(int))  # Ensure predictions are integers\n",
        "        # Majority vote (for each sample)\n",
        "        tree_predictions = np.array(tree_predictions)\n",
        "        final_predictions = []\n",
        "        for i in range(X.shape[0]):\n",
        "            votes = tree_predictions[:, i]\n",
        "            majority_vote = np.bincount(votes).argmax()\n",
        "            final_predictions.append(majority_vote)\n",
        "\n",
        "        return final_predictions\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hyyEBta8yNvt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}